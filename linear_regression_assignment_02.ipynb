{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "linear_regression_assignment_02.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.7.6 64-bit ('base': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "a5653b54fe6cf6e2fae9bcefb5bfcf782e994099dd1c9a4571168f76f9b0455a"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Matheuss1/artificial-intelligence-and-what-is-behind/blob/assignment-02/linear_regression_assignment_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tarefa \\#2**: Machine Learning MC886/MO444\n",
        "##**Regressão Linear**##\n",
        "\n",
        "Universidade Estadual de Campinas (Unicamp)\n",
        "\n",
        "Instituto de Computação (IC)\n",
        "\n",
        "Prof. Marcelo Reis\n",
        "\n"
      ],
      "metadata": {
        "id": "Cs9E_R5yD48u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "# TODO: RA & Name \n",
        "print('241882: ' + 'Matheus Silva de Deus')\n",
        "print('186447: ' + 'Renan Borges Alves')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "241882: Matheus Silva de Deus\n",
            "186447: Renan Borges Alves\n"
          ]
        }
      ],
      "metadata": {
        "id": "tFS9Oum_RJX9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3efd9f21-d278-4705-81da-76268d287892"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Objective: Predict life expectancy. \n",
        "\n",
        "Explore **linear regression** alternatives and come up with the best possible model to the problems, avoiding overfitting. In particular, predict the **Life expectancy** from their attributes."
      ],
      "metadata": {
        "id": "IVGH2s7fD_03"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "\n",
        "The purpose of this dataset is to do health data analysis. The dataset related to life expectancy, health factors for 193 countries was collected from the same WHO data repository website and their corresponding economic data were collected from the United Nations website. Among all categories of health-related factors, only the critical factors that are most representative were chosen. All predictor variables were then divided into several broad categories: Immunization-related factors, Mortality factors, Economic factors, and Social factors.\n",
        "\n",
        "Dataset Information: You should respect the following traininig/test split: 2056 training examples, and 882 test examples.\n",
        "\n",
        "There are 22 attributes as follows: \n",
        "\n",
        "Data Dictionary\n",
        "\n",
        "- Country\t\n",
        "- Year\t\n",
        "- Status\t\t\n",
        "- Adult Mortality\t\n",
        "- infant deaths\t\n",
        "- Alcohol\t\n",
        "- percentage expenditure\t\n",
        "- Hepatitis B\t\n",
        "- Measles\t\n",
        "- BMI\t\n",
        "- under-five deaths\t\n",
        "- Polio\t\n",
        "- Total \n",
        "- expenditure\t\n",
        "- Diphtheria\t\n",
        "- HIV/AIDS\t\n",
        "- GDP\t\n",
        "- Population\t\n",
        "- thinness  1-19 years\t\n",
        "- thinness 5-9 years\t\n",
        "- Income composition of resources\tSchooling\n",
        "\n",
        "- **Life expectancy**\n",
        "\n",
        "\n",
        "The data is available at\n",
        "- train: https://tinyurl.com/5374623f\n",
        "- test: https://tinyurl.com/mtdkjf55\n"
      ],
      "metadata": {
        "id": "r3XDZRGqEwsk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Atividades\n",
        "\n",
        "1. (5 pontos) Faça a Regressão Linear. Você deve implemetar a sua própria solução e comparar com ```sklearn.linear_model.SGDRegressor``` (modelo linear calculado com gradiente descendente estocástico da biblioteca [scikit-learn](http://scikit-learn.org)).\n",
        "Não esqueça que o conjunto de testes NÃO deve ser utilizado para o **treinamento** do modelo.\n",
        "\n",
        "**Dica: Verifique o conjunto de dados. Existem outliers? Estão faltando valores em alguns campos? Como utilizar variáveis categóricas?**\n"
      ],
      "metadata": {
        "id": "5d495CmpCltx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "#import libs\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils import shuffle\n",
        "%matplotlib inline\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "3y0QxxH1KgE1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "# Tools to import the data to be used in this analysis\n",
        "\n",
        "class GoogleDriveSheetDataImporter:\n",
        "  @staticmethod\n",
        "  def importData(sheet_id):\n",
        "    url = f\"https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv\"\n",
        "\n",
        "    return pd.read_csv(url)\n",
        "\n",
        "TRAINING_DATA_SHEET_ID = '1ejB4RtHX6ma0XK51I6f_7AtDblKivlOtzSkxitdZYtA'\n",
        "TEST_DATA_SHEET_ID = '1PrY9blDscKw5gWTyA3S34Gj3H5rRpuUU_b9rhVFsPQc'"
      ],
      "outputs": [],
      "metadata": {
        "id": "1wxlQPwrISLF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "# Tools to preprocess data\n",
        "\n",
        "def convertStringDottedNumberToPythonInt(numberToConvert):\n",
        "  if pd.isna(numberToConvert):\n",
        "    return numberToConvert\n",
        "    \n",
        "  return int(numberToConvert.replace('.',''))\n",
        "\n",
        "  \n",
        "def applyToColumn(df, columnName, func):\n",
        "  df[columnName] = df[columnName].apply(func)\n",
        "  return df\n",
        "\n",
        "\n",
        "def replaceMissingValues(df):\n",
        "  numeric_columns = df.select_dtypes(include=np.number).columns\n",
        "\n",
        "  return  df[numeric_columns].fillna(df.mean())\n",
        "\n",
        "\n",
        "def meanNormalization(df):\n",
        "  return (df - df.mean()) / df.std()\n",
        "\n",
        "\n",
        "def getXValuesWithBiasIncludedInWeightsVector(X):\n",
        "  rows_number = len(X)\n",
        "\n",
        "  return np.c_[np.ones(rows_number), X]\n",
        "  "
      ],
      "outputs": [],
      "metadata": {
        "id": "a2yRyfQYISLF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "# Get the train and test dataframes\n",
        "\n",
        "train_df = GoogleDriveSheetDataImporter.importData(TRAINING_DATA_SHEET_ID)\n",
        "test_df = GoogleDriveSheetDataImporter.importData(TEST_DATA_SHEET_ID)"
      ],
      "outputs": [],
      "metadata": {
        "id": "tmdo-qgYISLG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "# Transform numbers in string format to python number type\n",
        "\n",
        "train_df = applyToColumn(train_df, 'percentage expenditure', convertStringDottedNumberToPythonInt)\n",
        "train_df = applyToColumn(train_df, 'GDP', convertStringDottedNumberToPythonInt)\n",
        "\n",
        "test_df = applyToColumn(test_df, 'percentage expenditure',convertStringDottedNumberToPythonInt)\n",
        "test_df = applyToColumn(test_df, 'GDP', convertStringDottedNumberToPythonInt)\n",
        "\n",
        "# Drop categorial variables (better results are given without them)\n",
        "COLUMNS_TO_DROP = ['Country', 'Status', 'Diphtheria']\n",
        "\n",
        "\n",
        "train_df = train_df.drop(columns=COLUMNS_TO_DROP)\n",
        "\n",
        "test_df = test_df.drop(columns=COLUMNS_TO_DROP)\n",
        "\n",
        "# Replace dataframe missing values (NaN)\n",
        "\n",
        "train_df = replaceMissingValues(train_df)\n",
        "test_df = replaceMissingValues(test_df)\n",
        "\n",
        "# Normalize dataframe data\n",
        "\n",
        "train_df = meanNormalization(train_df)\n",
        "test_df = meanNormalization(test_df)"
      ],
      "outputs": [],
      "metadata": {
        "id": "1r3rsMRuISLH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "X_train = train_df.loc[:, train_df.columns != 'Life expectancy'].values\n",
        "y_train = train_df['Life expectancy'].values\n",
        "\n",
        "X_test = test_df.loc[:, test_df.columns != 'Life expectancy'].values\n",
        "y_test = test_df['Life expectancy'].values\n",
        "\n",
        "# Add a column of ones, to use bias inside weights vector\n",
        "X_train = getXValuesWithBiasIncludedInWeightsVector(X_train)\n",
        "\n",
        "X_test = getXValuesWithBiasIncludedInWeightsVector(X_test)\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "gcdRTD4pajhb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "# TODO: Implemente aqui sua solução SEM utilizar bibliotecas prontas\n",
        "#       como scikit-learn, Keras/TensorFlow, ou PyTorch.\n",
        "\n",
        "rng = np.random.RandomState(0)\n",
        "\n",
        "# Mean Squared Error\n",
        "\n",
        "\n",
        "def mse_loss(y_pred, y_true):\n",
        "    np_y_pred = np.array(y_pred)\n",
        "    np_y_true = np.array(y_true)\n",
        "\n",
        "    return np.mean((np_y_true - np_y_pred)**2)\n",
        "\n",
        "\n",
        "def plot_history(model):\n",
        "    plt.plot(model.history)\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('iteration')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "class SGDRegression():\n",
        "    def __init__(self, learning_rate, max_iter):\n",
        "        self.max_iter = max_iter  # maximo de iteracoes\n",
        "        self.alpha = learning_rate  # taxa de aprendizado\n",
        "        self.ws = None  # pesos\n",
        "\n",
        "    def predict(self, X):\n",
        "        return X @ self.ws\n",
        "\n",
        "    # using sum of squares error to calculate the gradient\n",
        "    def update_weights(self, y_pred, target, sample):\n",
        "        n_weights = len(self.ws)\n",
        "        stochastic_gradient = []\n",
        "\n",
        "        for i in range(n_weights):\n",
        "            wi_derivative = -2 * sample[i] * (y_pred - target)\n",
        "\n",
        "            stochastic_gradient.append(wi_derivative)\n",
        "\n",
        "        self.ws = self.ws - (self.alpha * np.array(stochastic_gradient))\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        if self.ws is None:\n",
        "            # init random weights\n",
        "            ws = rng.randn(X.shape[1])\n",
        "            self.ws = ws\n",
        "        assert X.shape[0] == y.shape[0]\n",
        "\n",
        "        history = []  # lista para guardar os valores de loss\n",
        "        for i in range(self.max_iter):\n",
        "            X, y = shuffle(X, y, random_state=0)\n",
        "            avg_loss = []\n",
        "            for sample, target in zip(X, y):\n",
        "                y_pred = self.predict(sample)\n",
        "                loss = mse_loss(y_pred, target)\n",
        "                avg_loss.append(loss)\n",
        "                self.update_weights(y_pred, target, sample)\n",
        "            history.append((sum(avg_loss)/len(avg_loss)))\n",
        "        self.history = history\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "VuguYJ1baer1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "================================ COMEÇO EQUAÇÃO NORMAL ================================"
      ],
      "metadata": {
        "id": "FmqXuu7L-M_b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate theta_values - Normal Equation\n",
        "theta_values=np.linalg.inv(X_train.T.dot(X_train)).dot(X_train.T).dot(y_train)\n",
        "\n",
        "#predict values of y with normal equation\n",
        "y_pred_normal=X_test.dot(theta_values)\n",
        "#calculate MSE\n",
        "mse_loss(y_pred_normal, y_test)"
      ],
      "metadata": {
        "id": "gbFQujcI-UI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "================================ TÉRMINO EQUAÇÃO NORMAL ================================"
      ],
      "metadata": {
        "id": "18ZGY7-b-bAU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "lr = 10e-9 \n",
        "max_iter = 1000\n",
        "sgd_linear = SGDRegression(learning_rate=lr, max_iter=max_iter)\n",
        "sgd_linear.fit(X_train, y_train)\n",
        "print('W = ', sgd_linear.ws)"
      ],
      "outputs": [],
      "metadata": {
        "id": "D9cpdif9JxFR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Loss evolution over time\n",
        "plot_history(sgd_linear)"
      ],
      "outputs": [],
      "metadata": {
        "id": "KENWt3bBudE1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# MSE loss in test set\n",
        "y_pred = sgd_linear.predict(X_test)\n",
        "\n",
        "mse_loss(y_pred, y_test)"
      ],
      "outputs": [],
      "metadata": {
        "id": "jKRlMgx8uZcu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from sklearn.linear_model import SGDRegressor\n",
        "\n",
        "reg = SGDRegressor(max_iter=1000, tol=1e-3, shuffle=True)\n",
        "\n",
        "reg.fit(X_train, y_train)\n",
        "\n",
        "print('W = ', reg.coef_)"
      ],
      "outputs": [],
      "metadata": {
        "id": "e4nZrMr_C2X7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# MSE loss in test set using sklearn SGDRegressor\n",
        "y_pred = reg.predict(X_test)\n",
        "\n",
        "mse_loss(y_pred, y_test)"
      ],
      "outputs": [],
      "metadata": {
        "id": "VswOZJb3vC_c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        ">**Quais são as suas conclusões? (1-2 parágrafos)**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zBNZQNImKQeo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. (2 points) Treine o modelo de regressão linear otimizado com Gradiente Descendente (GD) com 3 taxas de aprendizado diferentes. Compare os resultados dos modelos de GD com a solução com a equação normal (pseudo-inversa). "
      ],
      "metadata": {
        "id": "ADxPBRhuK_Vq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# TODO: Gradiente Descente (GD) com 3 taxas de aprendizado diferentes. \n",
        "lr1 = -1 #substitua por uma taxa de aprendizado válida\n",
        "max_iter = -1 #substitua por um número máximo de iterações válido\n",
        "sgd_linear_lr1 = SGDRegression(learning_rate=lr1, max_iter=max_iter)\n",
        "sgd_linear_lr1.fit(X_train, y_train) #treinamento\n",
        "print('Taxa de aprendizado = ', lr1, ' W = ', sgd_linear_lr1.ws)\n",
        "\n",
        "lr2 = -1 #substitua por uma taxa de aprendizado válida\n",
        "max_iter = -1 #substitua por um número máximo de iterações válido\n",
        "sgd_linear_lr2 = SGDRegression(learning_rate=lr2, max_iter=max_iter)\n",
        "sgd_linear_lr2.fit(X_train, y_train) #treinamento\n",
        "print('Taxa de aprendizado = ', lr2, ' W = ', sgd_linear_lr2.ws)\n",
        "\n",
        "lr3 = -1 #substitua por uma taxa de aprendizado válida\n",
        "max_iter = -1 #substitua por um número máximo de iterações válido\n",
        "sgd_linear_lr3 = SGDRegression(learning_rate=lr3, max_iter=max_iter)\n",
        "sgd_linear_lr3.fit(X_train, y_train) #treinamento\n",
        "print('Taxa de aprendizado = ', lr3, ' W = ', sgd_linear_lr3.ws)"
      ],
      "outputs": [],
      "metadata": {
        "id": "RSZ1pLItNVbU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Calcule e compare o MSE no conjunto de testes para cada modelo"
      ],
      "outputs": [],
      "metadata": {
        "id": "bCPSK-5Tr68p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# TODO: Implemente aqui sua solução para regressão linear com equação normal\n",
        "\n",
        "class NERegression():\n",
        "    def __init__(self):\n",
        "      self.ws = None #pesos\n",
        "    \n",
        "    def predict(self, X):\n",
        "      # Use essa função para calcular y a partir de X e ws. \n",
        "      # Não esqueça de adicionar o bias.\n",
        "      pass #remova essa linha\n",
        "\n",
        "    def fit(self, X, y):\n",
        "      #Use essa função para calcular a matriz de pesos com a equação normal\n",
        "      self.ws = None #Substitua pelo calculo da equação normal"
      ],
      "outputs": [],
      "metadata": {
        "id": "bOsDG8Kge3x_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#TODO: Calcule o modelo de regressão linear utilizando equação normal\n",
        "ne = NERegression()\n",
        "ne.fit(X_train, y_train)\n",
        "print(\"W = \", ne.ws)"
      ],
      "outputs": [],
      "metadata": {
        "id": "hqNlsGU1hZIp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Calcule o MSE no conjunto de testes"
      ],
      "outputs": [],
      "metadata": {
        "id": "ZFS1xpPui2rj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "   > **Quais são as suas conclusões? (1-2 parágrafos):**\n"
      ],
      "metadata": {
        "id": "hrDXPt7mhj9z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. (2 points) Às vezes, funções mais complexas geram melhores predições. Desenvolva e avalie um modelo de regressão polinomial.\n",
        "\n"
      ],
      "metadata": {
        "id": "XrPl7jKgJPW6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# TODO: Implemente aqui sua função para gerar um modelo de regressão polinomial.\n",
        "#       Não utilize bibliotecas prontas como scikit-learn, Keras/TensorFlow, ou PyTorch.\n",
        "\n",
        "class PolyFeatures():\n",
        "    def __init__(self, degree):\n",
        "      self.degree = degree #grau da nova matriz X\n",
        "\n",
        "    def transform(self, X):\n",
        "      #use essa função para gerar a nova matriz X\n",
        "      X_poly = None #substitua pela geração do X polinomial\n",
        "      return X_poly"
      ],
      "outputs": [],
      "metadata": {
        "id": "GjGbg41PMHR9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "degree = -1 #escolha o grau da regressão polinomial\n",
        "poly_feat = PolyFeatures(degree)\n",
        "X_train_poly = poly_feat.transform(X_train)"
      ],
      "outputs": [],
      "metadata": {
        "id": "i4Ayb9A4vh-e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "lr = -1 #substitua por uma taxa de aprendizado válida\n",
        "max_iter = -1 #substitua por um número máximo de iterações válido\n",
        "sgd_poly = SGDRegression(learning_rate=lr, max_iter=max_iter)\n",
        "sgd_poly.fit(X_train_poly, y_train) #treinamento\n",
        "print('W = ', sgd_poly.ws)"
      ],
      "outputs": [],
      "metadata": {
        "id": "SXE-I3KFx5Qe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Evolução da loss ao longo do tempo\n",
        "plot_history(sgd_poly)"
      ],
      "outputs": [],
      "metadata": {
        "id": "5iknRtHe05gB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        " > **Quais as suas conclusões?(1-2 parágrafos):**\n",
        "\n",
        " \n"
      ],
      "metadata": {
        "id": "rBLKtosaLaCw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. (1 point) Avalie os gráficos da função de custo vs. número de iterações no conjunto de treino. Quais conclusões você pode chegar a respeito dos modelos de GD ao analisar os gráficos?"
      ],
      "metadata": {
        "id": "ldSh1vtWK5Zk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print('Função de custo vs. Numero de iterações GD linear')\n",
        "plot_history(sgd_linear)"
      ],
      "outputs": [],
      "metadata": {
        "id": "mg7aNkl_LG4P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print('Função de custo vs. Numero de iterações GD linear com taxa de aprendizado =  ', lr1)\n",
        "plot_history(sgd_linear_lr1)"
      ],
      "outputs": [],
      "metadata": {
        "id": "3lPon5K2KDE-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print('Função de custo vs. Numero de iterações GD linear com taxa de aprendizado =  ', lr2)\n",
        "plot_history(sgd_linear_lr2)"
      ],
      "outputs": [],
      "metadata": {
        "id": "S5zm8CwbKIz_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print('Função de custo vs. Numero de iterações GD linear com taxa de aprendizado =  ', lr3)\n",
        "plot_history(sgd_linear_lr3)"
      ],
      "outputs": [],
      "metadata": {
        "id": "q4D-O0TeKMQb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print('Função de custo vs. Numero de iterações GD Polinomial')\n",
        "plot_history(sgd_poly)"
      ],
      "outputs": [],
      "metadata": {
        "id": "kh1waz6y4MbV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Escreva aqui suas conclusões (2-4 parágrafos)**\n"
      ],
      "metadata": {
        "id": "vbGOQzcsNSOm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prazo: 19 de Abril, Terça-feira, 23:59\n",
        "\n",
        "Política de penalidade para submissões atrasadas: Você não está sendo encorajada(o) a submeter o trabalho depois da data de submissão. Entretanto, caso isso aconteça, a nota será penalizada da seguinte forma:\n",
        "\n",
        "- 20 de Abril 23:59 : nota * 0.75\n",
        "- 21 de Abril 23:59 : nota * 0.5\n",
        "- 22 de Abril 23:59 : nota * 0.25\n"
      ],
      "metadata": {
        "id": "kdSGS4brHnAi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Submissão\n",
        "- Submita seu notebook no Google Classroom. (Em português ou inglês).\n",
        "\n",
        "- Apenas UMA pessoa da dupla precisa enviar o notebook.\n",
        "\n",
        "- Não esqueça de colocar seus respectivos nomes & RAs.\n",
        "\n",
        "- **Esta atividade NÃO é individual, deve ser realizada em dupla.**"
      ],
      "metadata": {
        "id": "joN9pvZJIfW5"
      }
    }
  ]
}